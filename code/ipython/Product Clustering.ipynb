{
 "metadata": {
  "name": "",
  "signature": "sha256:fc82f3c36d6c4caafda29294e5535e4aa6b3f1c802cdf00d862f654345a54a70"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from __future__ import division\n",
      "import os\n",
      "current_dir = os.getcwd()\n",
      "data_dir = os.path.join(current_dir, 'data')\n",
      "if not os.path.exists(data_dir):\n",
      "    os.mkdir(data_dir)\n",
      "    \n",
      "graph_dir = os.path.join(current_dir, 'graph')\n",
      "if not os.path.exists(graph_dir):\n",
      "    os.mkdir(graph_dir)\n",
      "    \n",
      "figure_dir = os.path.join(current_dir, 'figure')\n",
      "if not os.path.exists(figure_dir):\n",
      "    os.mkdir(figure_dir)\n",
      "\n",
      "import matplotlib.pylab as plt\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy.spatial.distance import pdist\n",
      "from sklearn import preprocessing\n",
      "\n",
      "import itertools\n",
      "\n",
      "import pandas.io.sql as psql\n",
      "import pymysql as mdb\n",
      "\n",
      "from datetime import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Get product information"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# establish connection\n",
      "db = mdb.connect(user=\"root\", host=\"localhost\", db=\"shoptiques\", charset=\"utf8\")\n",
      "\n",
      "# features of product we want to use\n",
      "\"\"\"\n",
      "product table:\n",
      "brand_id, fiber_content, made_in, product_size_type, retail price, size_and_fit_id, \n",
      "supplier_id, tags for the product, neighborhood(boutiques), name(word2vec), description(NLP)\n",
      "\n",
      "product_category table:\n",
      "name_code, lb_weight\n",
      "\n",
      "product_collection table:\n",
      "name\n",
      "\n",
      "product_neighborhood:\n",
      "neighborhood_id\n",
      "\n",
      "product_tags:\n",
      "\"\"\"\n",
      "\n",
      "# first let's get attributes from product table\n",
      "# for simplicity, let's take retail_price out first\n",
      "select_str = \"\"\"\n",
      "            SELECT product.id, product.brand_id, product.fiber_content, \n",
      "                    product.made_in, product.product_size_type, product.size_and_fit_id,                   \n",
      "                    product.supplier_id, product.name_code, product.retail_price,\n",
      "                    product_tags.tag_id\n",
      "                FROM product\n",
      "                    LEFT JOIN (product_tags)\n",
      "                        ON (product_tags.product_id = product.id)\n",
      "            ;\n",
      "\"\"\"\n",
      "\n",
      "product_df = psql.read_sql(select_str, db, index_col = 'id')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# auxillary functions for data preprocessing\n",
      "\n",
      "def find_frequent_item(df, col_name):\n",
      "    size_data = df.groupby(col_name).count()\n",
      "    ind = df[col_name].dropna().value_counts().index[0]\n",
      "    return ind"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# discritize the price data\n",
      "product_df.retail_price = pd.qcut(product_df.retail_price, 3, labels=['low', 'median', 'high'])\n",
      "\n",
      "# fix missing value\n",
      "for col in product_df.columns:\n",
      "    value = find_frequent_item(product_df, col)\n",
      "    product_df[col] = product_df[col].fillna(value)\n",
      "    \n",
      "# encoding the data\n",
      "le = preprocessing.LabelEncoder()\n",
      "product_df_encode = pd.DataFrame(map(le.fit_transform, product_df.T.values)).T\n",
      "product_df_encode.index = product_df.index\n",
      "product_df_encode.columns = product_df.columns\n",
      "\n",
      "file_name = \"product_{0.month}_{0.day}_{0.year}.csv\".format(datetime.now())\n",
      "product_df_encode.to_csv(os.path.join(data_dir, file_name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now calculate hamming distance between products\n",
      "dist = pdist(product_df_encode.values, 'hamming')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(dist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2917143153\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def round1(x):\n",
      "    return round(x, 1)\n",
      "\n",
      "dist_round = apply(round1, dist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_name = \"dist_product_{0.month}_{0.day}_{0.year}.csv\".format(datetime.now())\n",
      "pd.DataFrame(dist).to_csv(os.path.join(data_dir, file_name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time\n",
      "import Queue\n",
      "import threading\n",
      "\n",
      "condensed_idx = lambda i,j,n : int(i*n + j - i*(i+1)/2 - i - 1)\n",
      "\n",
      "nrows = product_df_encode.shape[0]\n",
      "\n",
      "row_indices = range(nrows-1)\n",
      "chunk = 10\n",
      "row_indices_chunks = zip(*[iter(row_indices)]*chunk)\n",
      "\n",
      "q = Queue.Queue()\n",
      "\n",
      "def assign_edges(q, inds):\n",
      "        edges = []\n",
      "        for i in inds:\n",
      "                for j in range(i+1, nrows):\n",
      "                        if dist[condensed_idx(i, j, nrows)] < 0.5:\n",
      "                                edges.append([i, j])\n",
      "        q.put(edges)\n",
      "\n",
      "for inds in row_indices_chunks:\n",
      "        t = threading.Thread(target=assign_edges, args=(q, inds))\n",
      "        t.daemon = True\n",
      "        t.start()\n",
      "\n",
      "edges = q.get()\n",
      "print edges[:10]\n",
      "# edges_df = pd.DataFrame(edges)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3 \u00b5s, sys: 1e+03 ns, total: 4 \u00b5s\n",
        "Wall time: 5.96 \u00b5s\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-23-f643300554ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massign_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yantan/anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yantan/anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yantan/anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Construct Graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "G = nx.Graph(edges)\n",
      "\n",
      "# write gml file\n",
      "file_name = \"edges_0.5_{0.month}_{0.day}_{0.year}.gml\".format(datetime.now())\n",
      "nx.write_gml(G, os.path.join(graph_dir, file_name))\n",
      "\n",
      "# degree_sequence = pd.Series(nx.degree(G).values())\n",
      "# np.log2(degree_sequence).hist(bins=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from igraph import *\n",
      "g = Graph.Read_GML(os.path.join(graph_dir, file_name))\n",
      "\n",
      "dendrogram = g.community_fastgreedy()\n",
      "clusters = dendrogram.as_clustering()\n",
      "membership = clusters.membership\n",
      "\n",
      "clustering = []\n",
      "n_items = []\n",
      "for i, cluster in enumerate(clusters):\n",
      "    n_items.append(len(cluster))\n",
      "    for node in cluster:\n",
      "        clustering.append((g.vs[node]['label'], i))\n",
      "\n",
      "clustering = pd.DataFrame(clustering)\n",
      "file_name = \"fastcommunity_clustering_edges_0.5_{0.month}_{0.day}_{0.year}.csv\".format(datetime.now())\n",
      "clustering.to_csv(os.path.join(graph_dir, file_name))\n",
      "\n",
      "n_items = pd.Series(n_items)\n",
      "n_items.plot('bar')\n",
      "plt.title(\"Cluster Size\")\n",
      "plt.savefig(os.path.join(figure_dir, \"fastcommunity_cluster_size.jpg\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}